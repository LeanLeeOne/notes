## 简述

**Doris**的计算和存储是耦合的，而分离的两者更适应云服务。



## 列式存储

**Doris**采用列式存储（ORCFile），支持按列进行压缩，有效节省了IO、CPU。

除了压缩，**Doris**还会对数据排序，并在此基础上，按一定的粒度（一千行、一万行、十万行）创建稀疏索引，而多数分析型数据库只会直接创建稀疏索引。有序的数据，对于`min()`、`max()`、`sum()`等聚合操作，能有效缩小查询范围，提升读性能。

**Doris**的存储类似于SST（[Sorted String Table](../09、Lucene/5.3 刷写、合并、切分#sorted-string-table)）。



## 导入

**Doris**的每一个数据导入作业，都是一个事务操作。

导入事务可以保证一批次内的数据原子生效，不会出现部分数据写入的情况。

同时，一个导入作业都会有一个Label。这个Label是在一个数据库（Database）下唯一的，用于唯一标识一个导入作业。Label可以由用户指定，部分导入功能也会由系统自动生成。

> Label是用于保证对应的导入作业，仅能成功导入一次。一个被成功导入的Label，再次使用时，会被拒绝并报错`Label already used`。通过这个机制，可以在**Doris**侧做到`At-Most-Once`语义。如果结合上游系统的`At-Least-Once`语义，则可以实现导入数据的`Exactly-Once`语义。

| 导入方式                                                     | 使用场景                                                     | 支持的文件格式          | 导入模式 |
| :----------------------------------------------------------- | :----------------------------------------------------------- | ----------------------- | -------- |
| [MySQL Load](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/mysql-load-manual/) | 导入本地文件，`LOAD DATA`                                    | csv                     | 同步     |
| [INSERT INTO VALUES](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/insert-into-manual/) | 通过JDBC等接口导入                                           | SQL                     | 同步     |
| [INSERT INTO SELECT](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/insert-into-manual/) | 导入外部表（如Hive、JDBC、Iceberg等）或者对象存储、HDFS中的文件 | SQL                     | 同步     |
| [Stream Load](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/stream-load-manual/) | 导入本地文件或者应用程序写入                                 | csv、json、parquet、orc | 同步     |
| [Broker Load](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/broker-load-manual/) | 导入对象存储、HDFS中的文件                                   | csv、json、parquet、orc | 异步     |
| [Routine Load](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/routine-load-manual/) | 从Kafka实时导入                                              | csv、json               | 异步     |

Broker Load、Stream Load和Routine Load都支持对源数据进行过滤、映射和转换：

- 前置过滤：对读取到的原始数据进行一次过滤。
- 映射：定义源数据中的列。如果定义的列名和表中的列相同，则直接映射为表中的列。如果不同，则这个被定义的列可以用于之后的转换操作。
- 转换：将第一步中经过映射的列进行转换，可以使用内置表达式、函数、自定义函数进行转化，并重新映射到表中对应的列上。
- 后置过滤：对经过映射和转换后的列，通过表达式进行过滤。被过滤的数据行不会导入到系统中。

### [Stream Load](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/stream-load-manual#基本原理)

Stream Load通过HTTP直接向**Doris**导入本地数据，不依赖其他系统或组件。

> 对于Stream Load，文件大小控制在`10GB`以内，因为过大的文件会导致过大的失败重试代价。

Stream Load是同步命令：返回成功，则表示数据已经导入；返回失败，则表示数据没有导入。

### [Broker Load](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/broker-load-manual#基本原理)

Broker Load通过部署的Broker进程，读取外部存储上的数据进行导入。

Broker Load是异步命令：命令执行成功，只表示提交任务成功；导入是否成功，需要通过`SHOW LOAD`来查看。

> 引入Broker进程的目的，主要是用来针对不同的外部数据源，用户可以不同的Broker进程。
>
> Broker进程和BE进程分离的设计，能隔离错误，提升BE稳定性。

### [Routine Load](https://doris.apache.org/zh-CN/docs/4.x/data-operate/import/import-way/routine-load-manual#基本原理)

在提交Routine Load作业后，**Doris**会持续运行该作业，实时生成导入任务不断消费Kafka中的数据。

Routine Load支持`Exactly-Once`语义，保证数据不丢不重。



## Compaction

### Aggregate模型

在导入数据时，Aggregate模型会进行分级合并，即，把小文件合并成中文件，再把中文件合并成大文件，而没有采用大文件直接跟小文件合并的方式，因为后者存在更严重的读写放大。

在Aggregate模型中，数据聚合发生在`3`个阶段：

1. 每一批次数据导入的ETL阶段，都会对同一批次内的数据进行聚合。
2. <span style=background:#f8d2ff>Backend</span>进行Compaction时，会对已导入的不同批次的数据进行进一步的聚合。
3. 数据查询阶段，对于涉及到的数据，会进行对应的聚合。

数据的聚合程度，在不同时间可能不一致，但这对用户而言是透明的，因为**Doris**会在查询过程中自动加入聚合算子，来提供最终的聚合结果，即，保证对外展示的一致性。

> 但这种一致性保证，会在语义和性能方面存在[局限性](https://doris.apache.org/zh-CN/docs/dev/data-table/data-model#聚合模型的局限性)：
>
> - 在Aggregate模型的聚合列（Value）上，执行与聚合类型不一致的聚合类查询时，要注意语义。
> - 在某些查询中，这种一致性保证会极大地降低查询效率，例如`count(*)`查询时，**Doris**必须扫描所有的Key字段，并且经过聚合，才能得到正确的语义。对于频繁的`count(*)`查询，官方建议通过增加一个聚合类型为`SUM`/`REPLACE`、值恒为`1`的字段来模拟`count(*)`。

对于`REPLACE`这种聚合方式：

- 对于同一个导入批次中的数据，替换顺序不做保证。
- 对于不同导入批次中的数据，替换顺序可以保证，即，后一批次的数据会替换前一批次的。

### Unique模型

Unique模型的MOW，在导入阶段就会将被覆盖/更新的数据标记为删除，这样在查询时，所有被标记删除的数据都会在文件级别被过滤掉，即，消除掉了MOR中的数据聚合过程、读取出来的数据都是最新的，并且能够在多种情况下（尤其是聚合查询）支持多种谓词的下推，大幅提升查询性能。



## 冷热分离

**Doris**能自动识别冷热数据，减少不必要的重复BE/CE，节省IO、CPU。**Doris**能识别存储介质的类型（HDD或SSD），结合自动识别冷热数据，能在分区粒度上，自动进行冷热数据的迁移。

