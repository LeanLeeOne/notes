## 简述

**Spark**的调优[可分为](https://tech.meituan.com/2016/04/29/spark-tuning-basic.html)：开发调优、参数调优、数据倾斜调优等。



## 开发调优

### 持久化

尽可能地<span style=background:#c2e2ff>复用</span>**RDD**，以减少重复计算。但**RDD**除了在Shuffle时，会持久化为本地磁盘上的分区文件，供其它**RDD**取用外，在执行其它算子时，都需要从外部存储器中重新加载并重新计算。所以，对于需要<span style=background:#c2e2ff>复用</span>的**RDD**，还需要进行持久化，以节省开销。

> 同一份数据，只应该创建一个RDD：不要重复加载数据；如果一份数据已经存在<u>键值对</u>类型的**RDD**，就不要再创建单Key或单Value类型的**RDD**。
>
> 无论持久化与否，**RDD**仅限同一应用共享，不同应用之间只能通过显式保存的文件来共享。

**RDD**主要有`4`种持久化级别：

- *MEMORY_ONLY*：仅保存在内存中，不进行持久化。如果内存不够，则压根儿不会保存，每次操作还得从头加载、计算。
- *MEMORY_ONLY_SER*：仅保存在内存中，不进行持久化，但是会通过把**Partition**中的元素序列化为`byte[]`这种紧凑的方式保存。
- *MEMORY_AND_DISK*：如果内存不够，则将溢写到磁盘中。
- *MEMORY_AND_DISK_SER*：如果序列化后，内存仍然不够，则溢写到磁盘中。

> 在指定持久化级别的同时，还可指定副本的数量。副本主要用于容错。增加副本会增加磁盘、网络开销，一般不建议使用。
>
> “持久化”后的**RDD**均以<span style=background:#c2e2ff>文件</span>的形式进行保存，特别的，*MEMORY_ONLY*级别保存在内存中，在Shuffle时[无需先](https://andr-robot.github.io/Spark-Shuffle/#23-shuffle-write)输出到本地磁盘，而是直接分发给下游。
>
> **RDD**类似于RDBMS中的视图，而持久化**RDD**类似于RDBMS中的物化视图。

#### 选择

如果内存足够，则应使用*MEMORY_ONLY*，否则使用*MEMORY_ONLY_SER*。

> *MEMORY_ONLY_SER*的内存占用少，GC次数少。更重要的是，序列化虽然会有CPU开销，但如果*MEMORY_ONLY*装不下，而*MEMORY_ONLY_SER*装得下，那么这份开销就是值得的。

如果*MEMORY_ONLY_SER*都不行，说明数据集很大，则应直接使用*MEMORY_AND_DISK_SER*，而非*MEMORY_AND_DISK*。

### 共享变量

**Spark**提供了`3`种共享变量：

1. 常规变量：变量作为闭包的一部分在被序列化后传递给**Executor**，传递是单向的，且每次都需要随**Task**的分发而传输。
2. 广播变量：经序列化后发送给每个**Executor**，仅需传输一次，各**Executor**会缓存。
3. 累加器：累加器类似于广播变量，但广播变量是单向传递的，而**Driver**会将各个**Task**中的累加器进行聚合从而得到最终值。

> 累加器不止可以是数值类型，还可以是集合类型。
>
> [闭包](https://www.runoob.com/scala/scala-closures.html)，Closure，是一种函数，它引用到函数外定义的变量，而其定义的过程是将这个变量捕获而构成一个封闭的函数。

Map Join的基础就是广播变量，而广播变量还可用于缓存大变量。

### 预聚合

预聚合（`combine()`）可以减少磁盘IO、网络IO。

按Key来对<u>键值对</u>进行聚合的`3`个算子分别是`reduceByKey()`、`foldByKey`和`aggregateByKey()`，与`groupByKey()`相比，前者会在Map时进行`combine()`，故而效率更高。

### 其它技巧

使用`mapPartitions()`替换`map()`。使用`foreachPartitions()`替换`foreach()`。

> 在向RDBMS中导入数据时，`foreachPartitions()`比`foreach()`更有优势。

如果使用`filter()`后能过滤掉很多多余的数据，那么可以再使用`coalesce()`进一步合并**Partition**，以便**Task**保持合适的数量。

> `coalesce()`是合并分区，无Shuffle，`repartition()`根据Key进行重分区，会Shuffle。

如果`repartition()`完还需要`sort()`，那么可直接替换为`repartitionAndSortWithinPartitions()`，将两次Shuffle减少为一次。



## 参数调优

**Executor**以多线程的方式执行**Task**。

**Executor**的[Memory](https://blog.csdn.net/pre_tender/article/details/101517789)，主要分为`4`部分：

1. Storage Memory：供持久化**RDD**时使用的，默认占`60%`。
2. Execution Memory：供**Task**在Shuffle时拉取上游**Task**的输出、进行聚合操作时使用的，默认占`20%`。
3. Other Memory：供**Task**执行业务代码时使用的，默认占`20%`。
4. Reserved Memory：预留内存，降低`OutOfMemoryError`风险。

> **Spark 1.5**后，Storage Memory和Execution Memory的分配由静态改为了动态共享，避免了内存的闲置。内存配额也由Storage Memory、Execution Memory各占`60%`、`20%`改为了共占`60%`。
>
> **Spark**对堆内内存采用的是“规划式”管理，即只在申请后和释放前记录这些内存，而对象实例占用内存的申请和释放都由JVM完成。这意味着**Spark**无法精确统计内存使用量，所以才需要Reserved Memory。
>
> **Spark 1.6**引入了[堆外内存](../03、JVM/3 垃圾收集#堆外内存4)，堆外内存由Storage Memory和Execution Memory共享。

**Spark**提供以下参数用于调整上述内容：

- `driver-memory`：**Driver**的Memory，只要不导致`OutOfMemoryError`就行，一般不需要设置。
- `num-executors`：**Executor**的总数。**Executor**过少，则并发度过低，应用执行慢；**Executor**过多，导致创建**Executor**时的开销、网络IO开销占比增大，浪费资源，且还会挤占资源。
- `executor-cores`：每个**Executor**能同时执行的**Task**的数量。
- `executor-memory`：每个**Executor**的Memory。Memory过小会导致`OutOfMemoryError`，过大则会挤占资源。
- `spark.default.parallelism`：默认并行度，可影响**RDD**的**Partition**数，进而影响**Task**数。
- `spark.storage.memoryFraction`：供持久化时使用的内存占比。
- `spark.shuffle.memoryFraction`：供Shuffle时使用的内存占比。

### 分区数

**Stage**中的**Task**的数量由该**Stage**中最后一个**RDD**的**Partition**的数量所决定，而**Partition**的数量[因创建方式的不同而不同](https://www.jianshu.com/p/4b7d07e754fa)：

- 通过非Shuffle<span style=background:#ffb8b8>转换</span>而来：其分区数与父**RDD**的分区数相同。
- 通过Shuffle<span style=background:#ffb8b8>转换</span>而来：若已指定分区数，则使用指定值；否则使用`spark.default.defaultParallelism`。
  - [如](https://spark.apache.org/docs/latest/configuration.html#execution-behavior)，`join()`、`reduceByKey()`。
  - `parallelize()`比较特殊，虽不是Shuffle<span style=background:#ffb8b8>转换</span>，但分区规则相同。
- **Spark SQL**中`JOIN`、聚合等Shuffle会使用的分区数：`spark.sql.shuffle.partitions`。
- 从外部存储器加载来创建：
  - **HDFS**：若已指定分区数，取指定的分区数与**Block**数中的最大值；若未指定分区数，取**Block**数、`spark.context.defaultMinPartitions`中的最大值。
  - **HBase**：取**Regin**数。
  - **Kafka**：取**Partition**数。

`spark.context.defaultParallelism`和`spark.context.defaultMinPartitions`分别取自`spark.default.parallelism`和`min(spark.default.parallelism, 2)`。

在**YARN**中，`spark.default.parallelism`等于`max(num-executors * executor-cores, 2)`。但如果在配置文件或代码中指定了`spark.default.parallelism`，则`spark.default.parallelism`会更新为指定值。



## 数据倾斜调优⭐

> 在**Spark**中，要确定是否发生数据倾斜以及发生数据倾斜的环节，需要结合Spark Web UI中**Task**的执行时长、日志、**Task**对应的代码是否涉及Shuffle、数据集的分布情况（`sample()`）来综合判断。

**HiveQL**中[数据倾斜解决方法](./6.1 HiveQL#数据倾斜⭐)，同样适用于**Spark**。

