## 简述

**RDD**是**Spark**最核心的概念。

- **RDD**是只读的、不可变的，但可以<span style=background:#ffb8b8>转换</span>为另一个新的**RDD**。
- **RDD**是分布式的，可以在不同节点存储同一数据集的不同**Partition**，并在此基础上进行带位置偏好的并行计算。
- **RDD**是弹性的，可以自动分区，可以自动容错（自动重新安排计算来重建丢失的**Partition**）。

> 只读、不可变，意味着不需要任何一致性维护。
>
> 除了从现有**RDD**<span style=background:#ffb8b8>转换</span>，**RDD**还可以通过从内存中的对象集合或从外部存储器加载来创建。
>
> **RDD**支持Hash和Range两种Partitioner。



## 算子

在**Spark**中，**RDD**的[操作](https://www.hadoopdoc.com/spark/spark-rdd-transformation-and-action)称为[算子](https://blog.csdn.net/a1043498776/article/details/77478151)，可分为`2`种。

- <span style=background:#ffb8b8>转换</span>，Transformation：从现有的**RDD**生成新的**RDD**。
- <span style=background:#f8d2ff>动作</span>，Action：触发对**RDD**的计算，然后将计算结果返回给**Driver**。

<span style=background:#ffb8b8>转换</span>是惰性的，<span style=background:#f8d2ff>动作</span>是立竿见影的：在对**RDD**执行<span style=background:#f8d2ff>动作</span>之前，不会执行任何的<span style=background:#ffb8b8>转换</span>。

> [在数学中](https://www.zhihu.com/question/24989360/answer/29702293)，函数是数到数的映射，泛函是函数到数的映射，算子是函数到函数的映射。在**Spark**中，算子可以理解为函数。
>
> 如果一个操作的返回类型是**RDD**，那么它是一个<span style=background:#ffb8b8>转换</span>，否则是一个<span style=background:#f8d2ff>动作</span>。

### 拓展

- <span style=background:#ffb8b8>转换</span>又分为`2`种：Value和<u>键值对</u>。
  - Value：`map()`、`flatMap()`、`mapPartitions()`、`glom()`、`groupBy()`、`filter()`、`distinct()`、`subtract()`、`union()`、`intersection()`、`cartesian()`、`sample()`、`takeSample()`、`cache()`、`persist()`、`sortBy()`等。
  - <u>键值对</u>：`mapValues()`、`combineByKey()`、`reduceByKey()`、`foldByKey`、`aggregateByKey()`、`groupByKey()`、`partitionBy()`、`cogroup()`、`join()`、`leftOutJoin()`、`rightOutJoin()`、`sortByKey()`、`coalesce()`、`repartition()`等。
- <span style=background:#f8d2ff>动作</span>可[分为`3`种](https://blog.csdn.net/jasonding1354/article/details/46848763)：
  - 无输出：`foreach()`、`mapPartitions()`。
  - 写入到外部存储器：`saveAsTextFile()`、`saveAsSequenceFile()`、`saveAsObjectFile()`。
  - 内存集合：`collect()`、`collectAsMap()`、`lookup()`、`count()`、`top()`、`countByKey()`、`countByValue()`、`take()`、[`reduce()`、`fold()`、`aggregate()`](https://www.jianshu.com/p/15739e95a46e)等。


> `map()`、`flatMap()`的区别在于对<u>集合类型的元素</u>的处理：
>
> - `map()`不会将<u>集合类型的元素</u>展开（flatten），长度为`N`的**RDD**转换后长度仍为`N`。
> - `flatMap()`会将<u>集合类型的元素</u>展开，并将这些<u>子元素</u>合并为一个新的**RDD**，新**RDD**的长度大于等于原**RDD**的长度`N`。
>
> `map()`、`mapValues()`的[区别](https://stackoverflow.com/questions/36696326/map-vs-mapvalues-in-spark)在于语义和分区：
>
> - `map()`即可接收单元素，也可接收<u>键值对</u>，且既可以处理Key，也可以处理Value；`mapValues()`只接收<u>键值对</u>，且仅可以处理Value。
> - `map()`会忽略自定义的Partitioner；`mapValues()`会使用自定义的Partitioner。（Repartition时，即便使用的是相同的Key，由于Partition信息的丢失，所以会强制执行Shuffle）
>
> `map()`、`mapPartitions()`的[区别](https://www.cnblogs.com/schoolbag/p/9640990.html)在于调用粒度上：
>
> - `map()`是细粒度的，采用直接遍历每个元素的方式。函数的调用次数多，对象的创建、销毁次数多，但内存占用小。
> - `mapPartitions()`是粗粒度的，采用的是遍历**Partition**，然后调用**Partition**的迭代器的方式来遍历每个元素的方式。函数的调用次数少，对象能重用，但内存占用多。
>
> 按Key来对<u>键值对</u>进行聚合的`3`个转换函数分别是`reduceByKey()`、`foldByKey`和`aggregateByKey()`，与`groupByKey()`相比，前者会在Map时进行预聚合（`combine()`），故而效率更高。
>
> 如果新旧**RDD**的Partitioner不一致，[会](https://www.cnblogs.com/duanxz/p/6327375.html)自动重分区（`partitionBy()`）。
>
> **MapReduce**会自动排序，但**Spark**需要手动指定。



## 依赖关系

![](../images/9/spark_rdd_dependency.png)

如[上图](http://shiyanjun.cn/archives/744.html)所示，有<span style=background:#ffb8b8>转换</span>就会有[依赖关系](https://bbs.pinggu.org/thread-4637506-1-1.html)，**Spark**将依赖分为`2`种：

- 窄依赖，Narrow Dependency：父**RDD**的**Partition**与子**RDD**的**Partition**之间是一对一、多对一的依赖关系。
- 宽依赖，Wide Dependency：父**RDD**的**Partition**与子**RDD**的**Partition**之间是多对多的依赖关系。

> 具有<u>宽依赖</u>关系的**Partition**间的<span style=background:#ffb8b8>转换</span>，其实就是Shuffle。
>
> 两个**RDD**，如果具有相同的Hash分区或Range分区，则其`JOIN`是<u>窄依赖</u>，否则是<u>宽依赖</u>。



## DAG

<img src="../images/9/spark_stages_and_RDDs_for_ word_counts.png" style="zoom:50%;" />

**Spark**应用由若干个**Job**组成，**Job**由若干**Stage**构成，**Stage**由若干**Task**组成。

> **Spark**以DAG的形式表示每个**Job**。
>
> Spark Web UI分别提供**Job**和**Stage**`2`种DAG，`2`种DAG的顶点不同，分别为**Stage**和**Task**。

当对**RDD**执行一个<span style=background:#f8d2ff>动作</span>时，**Driver**就会自动创建并提交一个**Job**。

**Stage**则根据**RDD**之间的依赖关系进行划分。

- <u>窄依赖</u>是确定性的，具有<u>窄依赖</u>关系的**RDD**分区的<span style=background:#ffb8b8>转换</span>可以在同一个线程中完成，所以会被划分到同一个**Stage**中。
- <u>宽依赖</u>是不确定性的，在<u>宽依赖</u>关系中，子**RDD**分区只能等父**RDD**分区Shuffle完后，才能开始计算，所以会被划分到不同的**Stage**中。
- 划分是从后往前进行的：遇到<u>宽依赖</u>就断开，划分出新的**Stage**；遇到<u>窄依赖</u>就将**RDD**加入到当前的**Stage**中。

> 在模型层面，**Job**之间没有依赖关系，**Stage**之间、**Task**之间往往有依赖关系。在业务逻辑层面，**Job**之间也可能有依赖关系。
>
> 惰性/延迟（Lazy）计算是为了划分**Stage**，以及合并同一**Stage**中的<span style=background:#ffb8b8>转换</span>。这是一种优化手段。
>
> 也可以说，**Stage**按照Shuffle进行划分。

**Stage**会根据**Partition**而横切为若干**Task**，每个**Task**包含若干**RDD**以及对**RDD**的<span style=background:#ffb8b8>转换</span>，换句话说，每个**Task**的处理逻辑完全相同，只是负责的**Partition**不同。**Stage**/**Task**分为`2`种：

- Shuffle Map：以Shuffle为输出边界，根据分区函数把结果写到本地磁盘上的一组新的**Partition**中，以便后续**Stage**/**Task**取用。后续**Stage**/**Task**可以是Shuffle Map，也可以是Result。
- Result：将结果返回给**Driver**。**Driver**会将每个**Partition**的结果进行汇总。

> **Stage**中的**Task**的数量由该**Stage**中最后一个**RDD**的**Partition**的数量所决定。



## 持久化

**RDD**在Shuffle之前虽然会持久化为本地磁盘上的分区文件，供其它**RDD**取用，但除此之外，每次操作**RDD**，都需要从外部存储器中重新加载并重新计算，所以，对于需要重用的**RDD**，可以进行持久化，以节省开销。

**RDD**主要有`4`种持久化级别：

- *MEMORY_ONLY*：仅保存在内存中，不进行持久化。如果内存不够，则压根儿不会保存，每次操作还得从头加载、计算。
- *MEMORY_ONLY_SER*：仅保存在内存中，不进行持久化，但是会通过把**Partition**中的元素序列化为字节数组这种紧凑的方式保存。序列化会有CPU开销，所以如果*MEMORY_ONLY*装不下，但*MEMORY_ONLY_SER*装得下，那么这份开销就是值得的。另外*MEMORY_ONLY_SER*还能减少GC。
- *MEMORY_AND_DISK*：如果内存不够，则将溢写到磁盘中。
- *MEMORY_AND_DISK_SER*：如果序列化后，内存仍然不够，则溢写到磁盘中。

> 在指定持久化级别的同时，还可指定副本的数量。副本主要用于容错。增加副本会增加磁盘、网络开销，一般不建议使用。
>
> “持久化”在内存中的**RDD**，在Shuffle时<span style=background:#ffee7c>todo</span>
>
> - 还是会先输出为本地磁盘上的**Partition**文件。
> - 会直接分发给下游，不会再基于文件。
>
> **RDD**类似于RDBMS中的视图，而持久化**RDD**类似于RDBMS中的物化视图。

如果内存足够，则应使用*MEMORY_ONLY*，否则使用*MEMORY_ONLY_SER*。如果*MEMORY_ONLY_SER*都不行，说明数据集很大，则应直接使用*MEMORY_AND_DISK_SER*，而非*MEMORY_AND_DISK*。

> **RDD**仅限同一应用共享，不同应用之间只能通过显式保存的文件来共享。


