## Sleuth

**Sleuth**提供服务间调用的链路追踪，以方便我们对服务进行好事分析、错误可视化、链路优化。

**Sleuth**通过在HTTP<u>请求头</u>上添加<u>Trace ID</u>和<u>Span ID</u>，来跟踪请求：

1. <u>Span ID</u>表示基本的工作单元，如，发送HTTP请求。
2. <u>Trace ID</u>包含一组<u>Span ID</u>，形成树状结构。
3. 当一个服务调用另一个服务时，<u>Trace ID</u>将保持不变。

**Sleuth**可与**Zipkin**搭配使用，将收集来的信息发送给**Zipkin**。



## Zipkin

**Zipkin**是一个分布式链路追踪系统，用于收集应用程序中需要排除延迟故障的时序信息。追踪请求在整个分布式系统中的调用链路，以此来推断系统的行为表现和各环节性能损耗。

**Zipkin**的工作流程分为3部分：

1. 生产记录

   1. **Zipkin**可用于多线程、RPC、HTTP等调用过程。
   2. 当应用系统接收到请求时，**Zipkin**会为请求赋予一个全局唯一的<u>Trace ID</u>。

2. 收集记录

   1. 可以通过**HTTP**将记录异步发送给**Zipkin**，之后持久化到**MySQL**、**Elasticsearch**等数据库中。
   2. 也可以通过写本地日志，使用**Logstash**等日志收集工具进行收集，最后持久化到**MySQL**、**Elasticsearch**中。

3. 记录查询展示

   1. 通过追踪<u>Trace ID</u>即可呈现整个调用链。

**Zipkin**的<u>Trace ID</u>采用ThreadLocalRandom类来生成的。



## ELK

**ELK**指的是**Elasticsearch**、**Logstash**和**Kibana**的组合：

1. **Elasticsearch**负责存储、实时搜索和分析（聚合统计）。
2. **Logstash**是一个服务器端数据处理管道，负责将多个源中的数据进行转换，然后发送给**Elasticsearch**。
3. **Kibana**负责对**Elasticsearch**中的数据可视化为图表。



## [大概流程](https://www.jianshu.com/p/092c43485637)

**Sleuth**截获HTTP调用，然后将必要的标记添加到<u>请求头</u>中。

服务接收到HTTP请求后，将数据异步发送到**Zipkin**。异步是为了防止与跟踪系统相关的延迟或故障延迟或破坏流。

**Sleuth**将<u>Trace ID</u>和<u>Span ID</u>添加到日志文件中。

**Logstash**收集日志，然后持久化到**MySQL**、**Elasticsearch**中。

> 也可以使用Beats，一个简单的数据传送器。Beats要么位于服务器上，要么位于容器上，用于监听日志文件的位置，然后将日志发送到**Logstash**中进行转换，或直接发送到**Elasticsearch**中。

