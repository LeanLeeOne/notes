## 消息幂等

**Kafka**不是严格的JMS， 没有对消息幂等作严格的要求，故消息不可靠，存在丢失、重复、错误、乱序等问题：

1. 在**Cluster**、**Producer**和**Consumer**中都有可能发生<span style=background:#f8d2ff>丢消息</span>。
2. **Producer**的超时重试，可能会导致**Broker**<span style=background:#c9ccff>重复接收</span>**Message**。
3. **Consumer**也存在<span style=background:#ffb8b8>重复消费</span>的可能。
4. **Consumer**可通过[递增版本号、状态机等方式解决](https://tech.meituan.com/2016/07/01/mq-design.html#消息延迟与忙等)乱序问题。



## 集群

### ACK

**Kafka**通过引入了ACK的概念来解决<span style=background:#f8d2ff>丢消息</span>：

1. 当**Cluster**保存**Message**后，会向**Producer**返回ACK；
2. 否则，**Producer**会进行有限<span style=background:#c2e2ff>重试</span>。

ACK的返回模式，对应参数<span style=background:#e6e6e6>request.required.acks</span>，有3种值：

| 值      | 动作                                                         | 向Producer报错 | 可能丢消息 |
| ------- | ------------------------------------------------------------ | -------------- | ---------- |
| 0       | 不返回ACK                                                    | ❌              | ✔          |
| 1       | 当**Leader**收到**Message**后，不等待**Follower**响应，立即返回ACK | ❌              | ✔          |
| -1(all) | 当**Leader**收到**Message**后，会等待所有的**Follower**返回ACK，<br/>之后才会向生产者返回ACK | ✔              | ❌          |

关于<span style=background:#e6e6e6>acks = -1</span>：

1. **Message**同步到**Replication**是发生在**Leader**<span style=background:#c2e2ff>刷盘</span>之后；**Follower**是在**Message**写入<span style=background:#c9ccff>Page Cache</span>后就会返回ACK。
2. 仅该模式需要维护**ISR**，其它模式不需要。

原理

**Kafka**[是靠LEO实现的防止<span style=background:#f8d2ff>丢消息</span>](https://honeypps.com/mq/deep-interpretation-of-kafka-data-reliability/#3-3-ISR)。

**Primary Partition**和**Replication**都记录自己最后一条**Message**的Offset，即，Log End Offset，LEO。

> 我愿将**Primary Partition**的**LEO**称为**Primary LEO**

而**ISR**中的**Replication**中最小的LEO，称作HighWatermark，HW。

> HW可以理解为木桶效应中的最短板。
>
> **Consumer**只被允许消费HW之前的**Message**。

当**Leader**和**Follower**完成同步后，**HW**也就和**Primary LEO**相等了。

如果在同步过程中，恰巧**Cluster**状态发生变化，触发重新选举，同步过程就会被打断。待选举完成后，**Leader**根据保存在**Zookeeper**中的**Primary LEO**和**HW**来判断同步是否完成，如果未完成：

1. 如果未完成，且<span style=background:#e6e6e6>acks = -1</span>，就会向**Producer**报错。
2. 如果未完成，**Leader**会要求**Follower**按照**HW**截断后，重新开始同步。

确切地说，**Message**确实丢了，但是**Producer**收到**Leader**反馈的错误后，可以通过重发消息进行补救。

> 由于**Follower**的同步进度不一，完成选举后，可能会出现<span style=background:#c9ccff>重复接收</span>的问题。



## 生产者

### 自行实现

**Producer**有2种发送模式：

| 模式 | 描述                                                         | 可能丢消息 |
| ---- | ------------------------------------------------------------ | ---------- |
| 同步 | 默认模式                                                     | ❌          |
| 异步 | 该模式会先将多条**Message**缓存，当缓存区满或者到时间周期后，进行<span style=background:#e6e6e6>批量发送</span> | ✔          |

> <span style=background:#e6e6e6>批量发送</span>减少了发送次数，也就减少无谓的请求头，也减少了ACK报个数，即，减少了IO、提升了效率。

<span style=background:#e6e6e6>批量发送</span>之所以会发生<span style=background:#f8d2ff>丢消息</span>，是因为：

1. 缓存位于内存中，易失；
2. 当**Producer**线程数不做限制，且**Message**生产速度过快时，当缓存已满时：
   1. 如果选择不阻塞线程，会多出来的**Message**会直接被丢掉；
   2. 如果选择阻塞线程，等待发送完毕，虽不会<span style=background:#f8d2ff>丢消息</span>，但会造成大量线程会挂起，内存占用不断增加，甚至应用崩溃。

缓解措施：

1. 持久化缓存中的消息；
2. 优化程序设计，控制**Message**生产速度，可以采用带阻塞的线程池；
3. 增大缓冲区空间，同时减小发送周期（当然提升有限，因为瓶颈在网络IO上）。

### 序列号及事务

另一种做法是，开启<span style=background:#b3b3b3>enable.idempotence = true</span> 。开启后，**Kafka**会为每个**Producer**生成一个ID，并为每条**Message**生成一个Sequence，当**Producer**对**Message**进行重试以防止<span style=background:#f8d2ff>丢消息</span>时，**Broker**[就会根据ID、Sequence进行判断](https://www.cnblogs.com/smartloli/p/11922639.html#3/8)，从而避免<span style=background:#c9ccff>重复接收</span>。

但是“ID + Sequence”的方法不能不能跨Session（**Producer**每次初始化都会向**Zookeeper**申请新的ID）、不能跨**Partition**，所以**Kafka**[推出了事务](https://matt33.com/2018/11/04/kafka-transaction/)：

1. **Producer**发送的消息要么提交，要么中断。
2. **Consumer**可通过设置参数来读已提交。

> **Kafka**的事务参考了2PC（Prepare、Commit），但进入Commit阶段后，无论**Producer**响应与否，**Broker**最终都会将**Message**提交，进而保证**Consistency**。



## 消费者

由于**Consumer**默认采用自动提交，即，收到**Message**后，立即响应，在之后的**Message**处理过程中可能存在<span style=background:#f8d2ff>丢消息</span>。

可改为手动提交，即，等**Message**处理完毕后，**Consumer**再响应，但这样一来又存在<span style=background:#ffb8b8>重复消费</span>的隐患。

同时，**Consumer**的**Rebalance**也会引发<span style=background:#ffb8b8>重复消费</span>。

<span style=background:#ffb8b8>重复消费</span>的解决方法有：

1. 本地消息表：
   1. 直接利用数据库的唯一索引来约束。
   2. 或者，在<u>更新操作</u>之前设置<u>前置操作</u>，只能从未提交、未处理，变更为处理成功、处理失败。
2. Token机制：
   1. 给**Message**分配全局唯一的ID，同时需要引入分布式事务和分布式锁来保证**Message**处理的原子性，所以对性能有一定影响。

