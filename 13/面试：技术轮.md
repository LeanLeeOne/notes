## 自我介绍

面试官好，我是李晓辉，来自山东，毕业自吉林大学，18年毕业之后就进入浪潮集团的公安事业部，从事相关系统的全栈开发。

疫情以来，部门的前景不明朗，工作内容也没有创造性，人往高处走，所以我选择了离职换工作。

- 离职之后，我将之前接触过的技术进行了深入的学习，积累了120篇、总计16万字的笔记。
- 当然，这些笔记多停留在理论层面，需要完善、实践的地方还有很多。

我在工作期间主要负责轨迹刻画、公安搜索引擎等系统的研发。

- 其中对轨迹刻画系统投入的精力比较多，除了前后端功能的开发，还对**HBase**表结构进行了优化，以及扩展了**Elasticsearch**的使用场景。
- 同时，我还承担了部分新技术的验证、引入，如引入**Kafka**、**Spring Cloud**等。

以上便是我的自我介绍。

> - 不明朗：疫情以来，部门都没有接到新的正式的项目，只有公司内部使用的新闻类网站的项目、安全生产检查这种与原有业务不相关的项目，而且不只是疫情，部门业务线、组织结构的频繁调整也影响了部门的前景。
> - 没有创造性：受部门发展的影响，相比于实习，以及刚入职时，那种经常学到新知识、攻克技术难点的工作状态，离职前的工作内容多是重复的脑力劳动、没有创造性。
> - 人往高处走：年轻人都有进互联网大厂的愿望，我也不例外，渴望进入大厂，与更优秀的人一起共事。当然，大厂的招聘要求也高，所以我也一直在努力提升自己。



## 印度短视频

### 负责功能

- #### 用户行为采集

  - 应用内转发，比起联系运维调整Nginx来说，更可控。
  - 小米侧向AWS侧转发的请求时，出现**403 Forbidden**（禁止访问）。
    - 排查过程：排除常见原因（白名单、跨Session），尝试直接通过IP访问，切换请求方法，补充日志。
    - 结论：转发请求时会自动将Host**原样**放入了新的请求头中，网关发现请求头中的Host与机器的实际的Host**不一致**，故禁止访问。
  - 异步转发请求时触及瓶颈（5万QPS），导致线程池阻塞，请求超时
    - 排查过程：对线程池进行调优，补充日志，统计出口QPS、连接耗时。
    - 结论：短连接导致**半连接**过多，连接池阻塞，改为**长连接**/**复用连接**。

- #### 小时报

  - 参数**调优**、性能**优化**
    - 合并、复用、缓存RDD ，以及减少不必要的去重/混洗
    - 参数调优，平衡并发度与资源抢占
    - 调整扩容策略，平衡速度与成本
    - 搭配使用S3与HDFS



## 公安轨迹刻画系统 v2.0 v3.0

### <span style=background:#ffb8b8>项目简述</span>

- **产品描述：**该系统将各类轨迹数据进行汇集，提供对象搜索、空间搜索。民警可通过该系统对各类重点人员的行踪进行监控预测。
- **技术选型：**该系统采用了微服务架构，使用**HBase**存储海量轨迹记录，使用**Elasticsearch**索引点位资源、近期轨迹记录，使用**Kafka**汇集分发数据，前端使用**Vue**进行了重构，并适配百度、高德、天地图等多种地图。
- **负责内容：**微服务化改造，优化**HBase**表结构，扩展了**Elasticsearch**的使用场景，将**Kafka**应用到系统，适配地图。

### <span style=background:#ffb8b8>使用说明</span>

- #### 数据来源

  - 从公安的各个业务系统中，将人员的各种轨迹，比如，铁路购票、旅馆住宿、卡口过车等原始数据，汇集到轨迹刻画系统的**HBase**中。
  - 以往是通过一个叫**IDI**的数据集成工具，对各类数据进行全量、增量、实时抽取，直接抽取到**HBase**的一张表中。
  - 引入**Kafka**后使用**Kafka**配合**IDI**进行抽取。
  - <span style=background:#c2e2ff>我们的系统几乎不生产数据，大部分时候只是数据的搬运工。</span>

- #### 搜索

  - ##### 以实体为中心搜索
    
    - 民警通过姓名、身份证号、车牌号确定某一实体，然后根据实体的ID到**HBase**中搜索轨迹数据，搜索结果会通过在地图上画线描点的方式进行展示。
    - 此外还提供散点图、连线图、饼图、柱状图等多种图表统计。
    - 民警可以对搜索结果进行时间、行为类型的过滤。
    
  - ##### 空间搜索

    - 同时，民警还可以直接在地图上绘制圆形、矩形、多边形来指定区域，系统会基于**Elasticsearch**进行区域搜索，将指定区域内的轨迹数据按时间倒序排列返回。
    
  - 除了对人、车进行搜索，还可以对点位进行搜索。

- #### 分析

  - 也是一种搜索，勾选源头表、上传表格，然后在页面上拼装查询条件，动态生成SQL，执行并返回结果。

- #### 布控

  - 对指定人员（上访、在逃、前科、吸毒）设置监控，当他们到达某些地点时就会触发警报，通知民警。

### <span style=background:#ffb8b8>架构设计</span>

- #### HBase行键

  - 系统采用了以实体为中心的查询方式，同时会有时间范围这种查询条件，所以对应的行键设计就采用了`身份证号+时间戳`这种设计方式。

  - 时间戳精确到毫秒，或追加随机数，或补充行为类型，来防止重复。

- #### HBase字段

  - 时间、地点（地点编号、地点名称、详细地址、经纬度）。

  - 行为类型、原始主键、身份证号。

  - 扩展字段1（终端号、座次、房间号）、扩展字段2（始发地、上机时间、退宿时间）（与<span style=background:#d4fe7f>Mark Word</span>相似，复用数据结构）。

- #### 微服务

  - 搜索：<u>以对象为中心的搜索</u>、<u>空间搜索</u>。

  - 分析：拼装SQL

  - 系统：用户角色、权限、资源的管理。

### <span style=background:#ffb8b8>负责功能</span>
- #### HBase表结构的优化

  - 去除对象ID这一字段。
  - 把地点编号、经纬度放入另一个列族。
  
  - 将始发地、目的地、过车速度等字段由扩展字段的方式改为自定义字段，充分利用**HBase**支持半结构化数据的特点。
  
- #### <span style=background:#19d02a>微服务化改造</span>⭐

  - 按照功能拆分为<u>搜索</u>、<u>分析</u>、<u>系统</u>三个子服务。
  - **Spring Cloud Netflix**与**Dubbo**
    - **Dubbo**专注于服务治理，最初是自成体系，并且停止维护了一段时间，而**Spring Cloud**覆盖全面，所以选择了**Spring Cloud**。
    - 但这种认识是比较局限的，**Dubbo**对标的是**Spring Cloud Netflix**，两者功能大同小异，并且现在**Dubbo**也已集成**Spring Cloud**中，名为**Spring Cloud Alibaba**，可以与**Spring Cloud**中的其它组件混用。
  - 配置提取，适配**Spring Boot**。
  - 改造动机
    - 主要是领导的决定，微服务化、容器化是趋势，引入新技术来对已有系统进行解耦、整合。
  - 微服务虽然是一项振奋人心、越来越流行的技术，微服务改造为我的项目带来了一些收益，但通过实践，我感觉它不适合政务行业。

    - <span style=background:#c9ccff>性能</span>
      - 单体架构对政务行业的绝大部分系统来说，足够了；单机不够，可采用<span style=background:#c2e2ff>Nginx+多机</span>的方式进行粗粒度的扩容，无需拆分成微服务进行细粒度的扩容。
      - 微服务之间通过网络进行通信，而非直接通过内存，与单体架构相比，增加了请求的时间、系统的复杂度。
    - <span style=background:#c9ccff>快速迭代</span>
      - 公安网与互联网隔离，需要到客户现场部署、调试，不便于进行快速迭代，除非驻场开发（对公司来说成本高）。
      - <span style=background:#c2e2ff>需求的快速响应、功能的快速开发、更新的快速上线倒是也适合政务行业。</span>范围小、低耦合。
      - 但交付之后，就不会再对系统进行大的升级迭代。
    - <span style=background:#c9ccff>解耦</span>
      - 微服务架构虽然解耦更彻底，但对于体量较小的应用，成本会高于收益。
      - 就单体架构，也能通过编码层的封装进行解耦。
    - <span style=background:#c9ccff>其它</span>
      - 在单体架构能满足需要的场景下，微服务架构只会增加开发、调试、部署时的工作量。
      - 我们从改造的开始就陷入了为了微服务而进行微服务改造的方向，服务划分的粒度、服务集群中实例的数量，都没有很好地把控。新技术虽然好，但不应盲目追求。
      - 通过实践微服务，还是学到了很多，积累了系统设计的经验。

- #### 丰富Elasticsearch的使用场景

  - 搜索近期轨迹。
  - 使用别名，进行冷热数据分离。

- #### Kafka

  - 使用**Kafka Connect**分发数据。
  - 将预警的延迟由分钟降到了秒。
    - 基于MQTT（订阅/发布）将信息发送到安卓应用，或者发送短信。

- #### ~~聚类分析~~

  - ~~过滤套牌车。~~

  - ~~DBSCN，具有噪声的基于密度的聚类方法。~~



## 公安大数据搜索引擎 v6.0

### <span style=background:#ffb8b8>项目简述</span>

- **产品描述：**该系统是一款面向公安的搜索引擎，旨在消除多警种之间的信息壁垒，提供人、车、案等对象档案的全面整合。
- **技术选型：**该系统使用NLP解析用户搜索意图，基于**Elasticsearch**进行检索，使用**HBase**存储对象档案、主题信息，并使用了**Spring Cloud**对功能模块进行解耦。
- **负责内容：**微服务化改造（框架搭建、网关开发、链路追踪、配置管理），轨迹、关系等子系统的整合，搜索引擎的开发，用户并发访问调优。

### <span style=background:#ffb8b8>使用说明</span>

- 搜索+详情。
- 与公安业务耦合，不够通用。

### <span style=background:#ffb8b8>架构设计</span>

- #### 档案

  - 消除部门壁垒，提供跨警种的搜索。
  - 汇聚常住人口/流动人口、各类证件、工作单位、人际关系、轨迹、名下车辆、涉及案件、照片库等多张源头表。
  - 以全量抽取+定期/定时维护的方式维护数据，通过身份证号将各种数据进行关联，关联后的数据放入**HBase**中。
  - 采用将源头表作为列族名的设计，但是这一设计不合理，应使用列，而非列族。

- #### 搜索

  - 该系统使用NLP解析用户搜索意图，基于**Elasticsearch**进行信息检索，基于**Elasticsearch**自身提供的文本相关度进行排序。

### <span style=background:#ffb8b8>负责功能</span>

- #### 微服务

  - 框架搭建
    - 服务治理、调用，限流、降级、熔断，
  - 将轨迹刻画、关系分析等子系统作为服务整合到搜索引擎中。
    - 搜索引擎与业务<span style=background:#c2e2ff>耦合</span>，完全可以将其解耦，应用于轨迹刻画、关系分析等系统。
  - 网关开发
    - 将瓦片路由的功能由**Tomcat**到**Nginx**到**Spring Cloud Gateway**，屏蔽掉瓦片服务器的具体地址，由网关进行统一代理。
    - 使用过滤器实现鉴权功能。
    - 熔断功能的开发：
      - 路由方案：失败的请求的URL的值变为了`Optional[forward:/defaultFallback]`，这根本没法用，故放弃“路由”方案。
      - 过滤器方案：基于网关提供的全局过滤器，对请求进行拦截，当请求连续失败到达一定阈值时，就将服务下线；进行了改进，将粒度变细，由服务细化为服务的接口。
  - 链路追踪
    - 使用**Sleuth**通过在HTTP请求头上添加Trace ID和Span ID，来跟踪请求，使用**Zipkin**配合**Logstash**收集日志，然后持久化到**Elasticsearch**中。
  
- #### 配置管理

  - 配置文件改为数据库中查询配置，热加载。

- #### 用户行为分析

  - 埋点、收集用户点击事件、查询事件，未做进一步的分析。

  - 关联档案推荐。

- #### 性能优化

  - 通过及时释放连接，将并发量由`200`提升到`500`。
  - 那如何由`500`提升至`5000`并发呢？（高吞吐 = 低延迟 + 高并发）
    - 多路复用。
    - 使用**Redis**提升响应速度。



## 挑战

### 线上故障

这倒没有，在交付前，我们都会进行充分的冗余设计、充分的测试来保证。

即便有，也可以结合日志、提交记录、堆快照等文件进行排查。

### 微服务化改造

- <span style=background:#19d02a>表现出自己敢于担当。</span>
- 从无到有，一开始对微服务的认识太浅，实践过程不顺利，实践后发现，微服务架构不适合政务行业。
- 调整了项目的打包方式来进行解决。

### Kafka Connect

- <span style=background:#19d02a>表现出自己强大的学习能力。</span>
- 技术选型
  - [HBase与ES的组合使用](https://jishuin.proginn.com/p/763bfbd59bff)的常见方案：
    - 双读双写：原理简单，需自行实现（重复造轮子）；**HBase**能扛得住、**Elasticsearch**不一定扛得住。
    - 自动复制：没有现成的（**MySQL**有，但**HBase**没有），需要自行开发，延迟较大。
    - 协处理器：加重**HBase**的负担；延迟较大；开发难度大。
    - 消息队列：没有明显缺点，**Kafka**还提供了现成的组件；基于延迟消费处理不一致。
  - 消息队列**Kafka**和**RocketMQ**
    - 性能上两者都满足需要，**Kafka**少主题写入性能好、**RocketMQ**抗消息堆积能力强。
    - **Kafka**生态更加完善，提供了丰富的**Connector**用来生产/消费数据，仅需通过配置即可，便捷、成本少，如有需要也可以改写源码。
- 从无到有，通过搜集资料、阅读调试源码来一步步摸索。
  - 关于主流数据源的资料比较全面，但是缺少关于**HBase**的资料，甚至**Apache**官网都没有提供。在一番搜索下，最终在其商业公司**Confluent**的官网上找到了相关JAR，从疑似开发者的博客中了解到向**HBase**中导入数据的过程。
  - 往**HBase**中写入数据，需要使用**KSQL**，**Kafka SQL**的意思。**Kafka**将自己定位为流处理工具，而非局限于消息队列，提供**KSQL**让开发者以**SQL**的形式操纵**Kafka**中的数据流，而这正是我所需要的。
    - 需要先使用**Avro**将键、值得解析模板进行注册，再进行数据导入。
    - 需要使用**KSQL**将原始主题中的数据分别转换成适用于**HBase**、**Elasticsearch**的格式，即，**HBase**使用列族，有两层，**Elasticsearch**的坐标使用结构体。
    - **HBase**还需要拼装行键，拼装规则也是通过阅读源码摸索出来的。
    - 当前版本的**Kafka**不支持**KSQL**中的结构体转换，幸运的是高版本支持。
- 用于改进监控功能。
  - <span style=background:#19d02a>表现出自己的责任心。</span>



## 技巧

投递和项目经历相关的岗位，准备和应聘岗位相关中间件。

标准的面试内容包括：

- 项目（适当美化）。
- 八股文。
- 算法题。

在面试时，可引导面试官，比如：

- 通过自我介绍来引导项目相关的提问。
- 通过项目介绍来引导后续关于中间件的提问。

另外，一定要表现得自信，即便心里很紧张，这样才能给面试官留下好印象。

