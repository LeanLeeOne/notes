## 块

Client会将一个完整的大文件分为若干**Block**，然后上传到**HDFS**的不同节点上。

每块**Block**大小固定，默认`128MB`，按<u>键值对</u>存储在**HDFS**上，并内存中保存<u>键值对</u>的映射。

> 如果最后的**Block**不足`128MB`也不要紧，[会按实际大小存储](https://blog.csdn.net/scgaliguodong123_/article/details/46315345#二数据存储操作)。
>
> **HDFS**为了追求高吞吐，而采用大文件的设计，这样能减少文件数量，从而减少寻道次数、网络交互次数、减少内存占用（[数据块映射等元数据](https://www.cnblogs.com/laov/p/3434917.html)少了，内存占用就少了）。
>
> **HDFS**专为存储大文件而设计，不擅长存取小文件。

**Block**采用流式数据访问，只允许在文件末尾追加写入，不支持修改已写入的内容。

如下，每个**Block**会额外有2个**Replication**，共计3份，以实现容灾。

```properties
block1:node1,node2,node3
block2:node2,node3,node4
block3:node4,mode5,node6
block4:node5,node6.node7
```



## 节点

![](../images/9/hadoop_node.svg)

**HDFS**有3种节点：<span style=background:#ffb8b8>Name Data</span>、<span style=background:#c9ccff>Secondary Name Data</span>、<span style=background:#f8d2ff>Data Node</span>。

### 命名节点

<span style=background:#ffb8b8>Name Data</span>负责维护<u>文件/目录树</u>，集中管理内存、IO，接收Client的操作请求。

<u>文件/目录树</u>保存有：

- 文件、目录的元信息。
- 文件分布信息：文件与**Block**的映射、**Block**与<span style=background:#f8d2ff>Data Node</span>的映射。

<span style=background:#ffb8b8>Name Data</span>直接在内存中维护整棵<u>文件/目录树</u>，但也会将<u>文件/目录树</u>持久化为文件：

- `fsimage`：<u>文件/目录树</u>的镜像。
- `edits`：保存对<u>文件/目录树</u>的修改日志。
- `fstime`：保存最近一次Checkpoint的时间。

<span style=background:#ffb8b8>Name Data</span>[启动时会加载](https://blog.csdn.net/woshiwanxin102213/article/details/19990487#3.4/8)`fsimage`、`edits`，在内存中重新生成<u>文件/目录树</u>，启动速度较慢。

为了提升启动速度，<span style=background:#ffb8b8>Name Data</span>会定时将`fsimage`、`edits`合并为新的`fsimage`。

### 辅助命名节点

不难看出，<span style=background:#ffb8b8>Name Data</span>的负担较重，同时，每个集群只有<span style=background:#ffb8b8>Name Data</span>，存在单点问题，所以每个集群还会配备一个<span style=background:#c9ccff>Secondary Name Data</span>。

<span style=background:#c9ccff>Secondary Name Data</span>会定时从<span style=background:#ffb8b8>Name Data</span>中获取`fsimage`、`edits`，并将两者合并为新的`fsimage`。

<span style=background:#c9ccff>Secondary Name Data</span>保存有`fsimage`、`edits`，有备用**Master**的作用，但不支持自动切换。

### 数据节点

<span style=background:#f8d2ff>Data Node</span>负责数据的读写，会定时向<span style=background:#ffb8b8>Name Data</span>发送心跳，报告自己所有的**Block**的列表。

如果<span style=background:#ffb8b8>Name Data</span>没能收到心跳，就会认为<span style=background:#f8d2ff>Data Node</span>失效，会将失效节点中的**Block**在其它节点上的**Replication**复制一份，并将这份**Replication**交给一个健康的节点。



## 读写[[1]](https://blog.csdn.net/scgaliguodong123_/article/details/46315345)

写入过程为：

1. Client将文件分为若干**Block**，并将这些**Block**顺序编号、放入<u>上传队列</u>中，将这些**Block**逐个上传到**HDFS**中。

2. Client每次向<span style=background:#ffb8b8>Name Data</span>请求时，<span style=background:#ffb8b8>Name Data</span>都会为Client分配一个新的**Block**，并将一组<span style=background:#f8d2ff>Data Node</span>的<u>地址列表</u>返回给Client。

   > <span style=background:#ffb8b8>Name Data</span>分配前会做各种校验：文件是否存在，Client是否有相应权限。

3. Client将的**Block**上传到<u>地址列表</u>中第一个<span style=background:#f8d2ff>Data Node</span>上，这个<span style=background:#f8d2ff>Data Node</span>又会将**Block**同步给列表中的第二台<span style=background:#f8d2ff>Data Node</span>，第二台又会向下一台同步，依此类推。

4. 等<u>地址列表</u>中所有<span style=background:#f8d2ff>Data Node</span>都保存后，这个**Block**才算上传完，才会变为可见的，然后上传下一个**Block**。

如果写入时发生错误，Client会请求将<span style=background:#f8d2ff>Data Node</span>上未写完的**Block**清理掉，Client向<u>地址列表</u>其它的<span style=background:#f8d2ff>Data Node</span>继续写入该**Block**，<span style=background:#ffb8b8>Name Data</span>会另外寻找一台<span style=background:#f8d2ff>Data Node</span>保存该**Block**。

![](../images/9/hdfs_write.png)

读取过程为：

1. Client向<span style=background:#ffb8b8>Name Data</span>请求文件，<span style=background:#ffb8b8>Name Data</span>向其返回文件的**Block**所在的<span style=background:#f8d2ff>Data Node</span>的地址，每次返回一个**Block**的一组<span style=background:#f8d2ff>Data Node</span>的地址。

   > 一个文件可能由多个**Block**组成，所以会分次读取。
   >
   > 因为**Block**存在副本，不同的副本往往会位于不同的<span style=background:#f8d2ff>Data Node</span>上。
   >
   > 这组<span style=background:#f8d2ff>Data Node</span>的地址按照拓扑结构排序，距离Client近的会排在前面。

2. Client从<u>地址列表</u>中选择离自己最近的<span style=background:#f8d2ff>Data Node</span>发起通信，以数据流的方式直接从该<span style=background:#f8d2ff>Data Node</span>中读取。

3. 读取完后Client会关闭连接，再次向<span style=background:#ffb8b8>Name Data</span>请求下一个**Block**的一批地址，然后重复刚才的读取过程。

如果与<span style=background:#f8d2ff>Data Node</span>的通信发生异常，Client会记录下这个<span style=background:#f8d2ff>Data Node</span>，然后从<u>地址列表</u>中选择一个下一个地址，发起连接，进行读取；后续的**Block**读取也会跳过刚才记录的<span style=background:#f8d2ff>Data Node</span>。

Client在读取时也会校验**Block**，会将损坏的**Block**报告给<span style=background:#ffb8b8>Name Data</span>，然后从其它的<span style=background:#f8d2ff>Data Node</span>重新读取该**Block**；<span style=background:#ffb8b8>Name Data</span>会从找到已损坏的**Block**的Replication，重新备份这份已损坏的**Block**。

![](../images/9/hdfs_read.png)



## 多机架[[2]](https://www.cnblogs.com/laov/p/3434917.html)

同一机架（机柜）中的节点之间的带宽，要大于不同机架中节点之间的带宽。

- 读取时，可以从不同的机架中的节点同时读取，充分利用多机架的带宽。
- 写入时，向多个机架中写入，效率会比较低，但能保证容灾。

所以，在开启机架感知（Rack Aware）后，

- 若Client为<span style=background:#f8d2ff>Data Node</span>，副本1会放于该节点上，副本2放于不同机架的节点上，副本3放于副本2所在机架的另一个节点上，其它副本随机放置。
- 若Client不为<span style=background:#f8d2ff>Data Node</span>，副本1随机选择一个节点放置，剩余副本的放置同上。

> 但也有[文章](https://www.cnblogs.com/duanxz/p/3874009.html#数据备份)说：**HDFS**会将前几个**Replication**放于同一机架中的不同节点上，并把最后一份**Replication**防于另一个机架的节点上；节点之间相互读取时，会优先读取同一机架上的副本。
>

![](../images/9/hdfs_rack_node.png)

