## 简述

**YARN**（Yet Another Resource Negotiator）的出现一方面是为了改善**Job Tracker**负担过重、功能耦合导致的可靠性、可扩展性、资源利用率不足等问题，另一方面是为了扩展**Hadoop**。

- 通过将**Job Tracker**拆分成<span style=background:#ffb8b8>Resource Manager</span>、<span style=background:#c9ccff>Application Master</span>解决了负担过重的问题。
- 通过将Job扩展为了Application，如[下图](https://blog.csdn.net/suifeng3051/article/details/49486927)所示，使**Hadoop**不仅支持**MapReduce**，还支持**Hive**、**HBase**、**Pig**、**Spark**/**Shark**等类型的应用，即，**YARN**令这些不同类型的应用互不干扰的运行在同一个**Hadoop**中。

> Application要么由一个Job组成，要么由一组DAG Job组成。
>
> DAG，Directed Acyclic Graph，有向无环图。

![](../images/9/yarn_function.png)



## 组件

如下图所示，**YARN**主要有以下组件：

<span style=background:#ffb8b8>Resource Manager</span>[[1]]()

- 全局级别的进程。
- <span style=background:#ffb8b8>Resource Manager</span>包含`3`个组件：
  - **Scheduler**：负责将<span style=background:#f8d2ff>Node Manager</span>上的**Container**分配给<span style=background:#c9ccff>Application Master</span>，共有FIFO、Capacity、Fair等`3`种。
  - **Application Manager**：负责管理<span style=background:#c9ccff>Application Master</span>，包括为<span style=background:#c9ccff>Application Master</span>申请**Container**、监控<span style=background:#c9ccff>Application Master</span>。
  - **Timeline Server**：负责存储应用历史。

<span style=background:#f8d2ff>Node Manager</span>[[2]](https://www.jianshu.com/p/01ff4f60afce)

- 节点级别的进程。
- 负责管理节点上的**Container**，包括创建**Container**、监控**Container**的运行状况、释放**Container**。
  - **Container**：是对CPU、内存等计算资源的抽象表示，所有应用都运行于其中，根据应用的需求动态生成。

<span style=background:#c9ccff>Application Master</span>

- 应用级别的进程。
- 是对运行在**YARN**中某个应用的抽象，负责切分数据、为Task申请**Container**、监控Task的运行状况，对于运行失败的Task会通过重新申请**Container**的方式来“重启”Task。

> 启动<span style=background:#f8d2ff>Node Manager</span>前，管理员需要先配置节点的可用资源（cpu-vcores、memory-mb），其中，CPU的个数时往往会几倍于物理CPU的核数，这样能细化资源量的粒度，并且物理性能越高的CPU，倍数越大，以缓解CPU异构wen'ti。
>
> <span style=background:#f8d2ff>Node Manager</span>在启动时会向<span style=background:#ffb8b8>Resource Manager</span>注册，并告知后者自己有多少可用资源。
>
> 不同的编程模型有不同的<span style=background:#c9ccff>Application Master</span>，用户可以参考官方配置模板中的`mapred-site.xml`配置来编写自己的<span style=background:#c9ccff>Application Master</span>。

![](../images/9/yarn_component.gif)


## 执行过程

如下图所示：

1. Client向<span style=background:#ffb8b8>Resource Manager</span>提交**Applicaton**。
2. <span style=background:#ffb8b8>Resource Manager</span>寻找一个可运行**Container**的<span style=background:#f8d2ff>Node Manager</span>，并在**Container**中启动一个<span style=background:#c9ccff>Application Master</span>实例。
3. <span style=background:#c9ccff>Application Master</span>启动后，向<span style=background:#ffb8b8>Resource Manager</span>注册，注册后Client就可通过<span style=background:#ffb8b8>Resource Manager</span>获取为其创建的<span style=background:#c9ccff>Application Master</span>的详细信息，然后Client与<span style=background:#c9ccff>Application Master</span>直接交互。
4. <span style=background:#c9ccff>Application Master</span>向<span style=background:#ffb8b8>Resource Manager</span>发送请求**Container**。
5. **Container**被分配完后，<span style=background:#ffb8b8>Resource Manager</span>会请求<span style=background:#f8d2ff>Node Manager</span>启动**Container**。
6. **Container**会把运行过程中进度、状态等信息发送给<span style=background:#c9ccff>Application Master</span>。
7. Client从<span style=background:#c9ccff>Application Master</span>中获取自己提交的应用的进度、运行状态等信息。
8. 当提交的应用执行完成，<span style=background:#c9ccff>Application Master</span>向<span style=background:#ffb8b8>Resource Manager</span>取消注册然后关闭，归还相应的**Container**。

![](../images/9/yarn_node.png)



## RPC协议

如[下图](https://www.cnblogs.com/liangzilx/p/14837562.html)所示，在**YARN**中，任何两个需相互通信的组件之间都有且仅有一个RPC协议，所有协议均采用Client/Server方式，除**ContainerManagementProtocol**采用的是Push通信模型（延迟低），其它协议均采用的是Pull通信模型。

- **ApplicationClientProtocol** ： Client通过该协议提交应用程序、查询应用程序状态等。
- **ResourceManagerAdministrationProtocol**： Admin通过该协议更新系统配置文件，比如节点黑白名单、用户队列权限等。
- **ApplicationMasterProtocol **：<span style=background:#c9ccff>Application Master</span>通过该协议向<span style=background:#ffb8b8>Resource Manager</span>注册和注销，以及为各个Task申请资源。
- **ContainerManagementProtocol** ：<span style=background:#c9ccff>Application Master</span>通过该协议令<span style=background:#f8d2ff>Node Manager</span>启动或者停止**Container**，以及获取各个**Container**的使用状态等信息。
- **ResourceTracker** ：<span style=background:#f8d2ff>Node Manager</span>通过该协议向<span style=background:#ffb8b8>Resource Manager</span>注册，并定时发送心跳信息汇报当前节点的资源使用情况和**Container**运行情况。

> 未能搜集到Client与<span style=background:#c9ccff>Application Master</span>之间的协议。

![](../images/9/yarn_rpc_protocol.svg)



## 资源隔离

资源隔离有多种实现方式：硬件虚拟化、虚拟机、Cgroups和LinuxContainer等。

**YARN**对内存和CPU采用了[不同的资源隔离方案](https://www.jianshu.com/p/01ff4f60afce)。

### 内存

内存是一种限制性资源，其大小直接决定了应用的死活。

**YARN**提供了2种方案：

1. 基于Cgroups的方案。
   1. Cgroups是Linux内核提供的弹性资源隔离机制，可以<u>严格</u>限制内存使用上限，一旦进程使用资源量超过事先定义的上限值，则可将其杀死。
2. 线程监控方案。
   1. 默认方案。
   2. 在这一方案中，各个Task运行在独立的JVM中以达到资源隔离的目的。由于Task可能会创建子进程，而JVM在创建子进程之后、执行子进程之前会复制一份父进程内存空间，从而导致**Container**的内存使用量翻番，容易导致误判，对此，**YARN**采用了线程监控的方法进行解决：<span style=background:#f8d2ff>Node Manager</span>会启动一个额外的线程来监控**Container**的内存使用量，并结合进程的“年龄”来判断内存使用量是否超标，一旦超标就会将其杀掉。

### CPU

CPU是一种弹性资源，其大小不会影响应用的死活，因此采用了Cgroups。

<span style=background:#f8d2ff>Node Manager</span>默认不开启对CPU的资源隔离。

