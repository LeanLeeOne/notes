## 概述

**Kafka**性能调优可以从以内存、磁盘、网络下几个方面进行：

1. Linux <span style=background:#c9ccff>Page Cache</span>参数调优。
   1. **Kafka**没有单独的Cache，它直接使用了<span style=background:#c9ccff>Page Cache</span>，由内核负责Cache的管理、垃圾收集。
   2. **Kafka**还使用了内存映射（MMap）来提高读写速度
2. **Broker**参数调优。
3. 开启压缩，**Producer**压缩，**Consumer**解压，以节省网络IO、提高吞吐。
   1. 压缩 / 解压会消耗CPU。
   2. **Kafka**支持Gzip、Snappy。
4. 按业务对集群进行资源隔离，避免不同业务因共享磁盘而相互影响。
5. 对集群用户的出入流量进行限制，避免流量突增。
6. 改造源码，对集群中的**Broker**，甚至是**Topic**进行流量限制。
7. 改造源码，对**Broker**进行<span style=background:#c2e2ff>负载均衡。</span>
8. 改造源码，实现副本并发、增量迁移，以减少IO。
9. 换用性能更好的固态硬盘，以及使用磁盘阵列。

**Kafka**基于Linux的<span style=background:#c9ccff>Page Cache</span>进行批量刷盘，而**Page**刷盘的触发条件有：

1. 调用<span style=background:#b3b3b3>sync()</span>、<span style=background:#b3b3b3>fsync()</span>。
2. 所占内存大于阈值。
3. **Dirty Data**到期。
   1. **Page**被标记为Dirty，并放入到**Dirty List**中，内核会周期性地的将**Dirty List**中的**Page**写入到磁盘中。

<span style=background:#c9ccff>Page Cache</span>过大会加剧：

1. 丢数据的风险。
2. 写入峰值，造成持续时间过长，占用磁盘资源。



## [基于SSD的Kafka缓存设计](https://tech.meituan.com/2021/01/14/kafka-ssd.html)

#### Kafka在高负载时存在的问题

当**Kafka**节点的负载过大时，同一节点上的不同**Partition**会出现竞争<span style=background:#c9ccff>Page Cache</span>的现象，相互影响，进而使该节点延迟上升、吞吐下降。

<span style=background:#c9ccff>Page Cache</span>在**Kafka**的读写（生产消费）过程中发挥了重要作用：

1. 生产到**Kafka**中的数据会先写入到<span style=background:#c9ccff>Page Cache</span>中，达到阈值后会进行刷盘。
2. 向**Kafka**请求数据时，也会先向<span style=background:#c9ccff>Page Cache</span>中请求，如果没有，才会去硬盘中读取放到网卡缓冲区（ZeroCopy，减少了用户态和内核态的切换）随后返回给消费者。

但**Consumer**的消费能力往往是不同的，在高负载的情况下，如果存在消费能力弱的**Consumer**，则<span style=background:#c9ccff>Page Cache</span>会被弱**Consumer**的数据占满，其他**Consumer**的数据会被大量刷写到硬盘上，这样强**Consumer**会失去<span style=background:#c9ccff>Page Cache</span>红利，而磁盘的读取也会增加，即延迟上升、吞吐下降。

而集群中往往存在着大量的弱**Consumer**，减少弱**Consumer**的方式不可行。

同时，传统机械硬盘的性能低，结合以上因素，美团为**Kafka**系统引入了固态硬盘作为缓存。（也可以纯修改软件，或者增大内存，但是这两种做法在美团看来太过复杂，并且不够经济）

#### 解决方法比较

开源的缓存技术FlashCache、OpenCAS都提供了四种缓存策略：

1. WriteThrough：同时向SSD和HDD写入。
2. WriteBack：写入SSD后就算写入成功，之后再Flush到HDD。
3. WirteAround：直接写入HDD。
4. WriteThrough / WriteBack / WriteAround：首先读取SSD，命中不了则读取HDD，并数据会被刷入SSD中。

但是这些缓存技术不能很好地解决问题：

1. 这些缓存技术的核心是“数据局部性”原理，与**Kafka**的读写特性不相符。

   1. 数据回刷会污染SSD。

3. 同时其数据淘汰策略为LRU，还是会淘汰近实时数据，造成抖动。

所以美团采用了从**Kafka**内部修改，使用SSD存放将实时数据，同时不允许HDD数据回刷到SSD，以防污染。

#### 具体方案

设计目标：

1. 将数据按时间维度分布，近实时数据放在SSD中，并随时间的推移淘汰到硬盘中
2. **Leader**分区中的所有数据写入SSD。
3. 从HDD中读取的数据不回刷到SSD。

想要HDD上的数据不回刷SSD上，我们需要对**Segment**的状态进行标记，包括：

1. OnlyCache：只存储到SSD上。
2. Cached：后台线程定期将内存中Inactive（没有写流量）的**Segment**同步到SSD上。
3. WithoutCache：当SSD的空间使用达到阈值时，后台线程会将最古老的**Segment**从SSD中移除，**Segment**的状态也会改为WithoutCache。

完成这些之后并不代表着优化工作的完成，还有<span style=background:#c2e2ff>数据同步</span>和<span style=background:#c2e2ff>刷盘策略</span>两个问题需要解决。

数据同步有2个关键问题：

1. 同步方式，出于对数据一致性维护成本、以及是否易于实现同步限速的考率，美团最终选择了，后台线程同步Inactive数据到HDD的方式。
2. 同步限速（最终一致性），显然，如果不对同步加以限速，数据会蜂拥而至，出现性能毛刺。

刷盘策略：

1. 对单个**Segment**刷盘速率进行限制。