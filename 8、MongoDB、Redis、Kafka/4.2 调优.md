## 概述

**Kafka**为了追求高吞吐，在内存、磁盘、网络等3个方面做了很多设计，包括顺序读写、分区、支持压缩、支持批量、数据结构（索引）、NIO+多路复用，以及<span style=background:#c9ccff>Page Cache</span>、Map、Zero Copy等。



## Kafka与Page Cache

**Kafka**没有单独的Cache，它使用**MMap**直接在<span style=background:#c9ccff>Page Cache</span>进行批量刷盘，由内核负责Cache的管理、垃圾收集。

<span style=background:#c9ccff>Page Cache</span>在**Kafka**的读写（生产消费）过程中发挥了重要作用：

1. 生产到**Kafka**中的数据会先写入到<span style=background:#c9ccff>Page Cache</span>中，达到阈值后会进行刷盘。

2. 向**Kafka**请求数据时，也会先向<span style=background:#c9ccff>Page Cache</span>中请求，如果没有，才会去硬盘中读取并放到网卡缓冲区，随后返回给消费者。

<span style=background:#c9ccff>Page Cache</span>过大会加剧：

1. 丢数据的风险。
2. 写入峰值，造成持续时间过长，占用磁盘资源。

<span style=background:#c9ccff>Page Cache</span>刷盘的触发条件有：

1. 调用<span style=background:#b3b3b3>sync()</span>、<span style=background:#b3b3b3>fsync()</span>。

2. 所占内存大于阈值。

3. **Dirty Data**到期。

   1. **Page**被标记为Dirty，并放入到**Dirty List**中，内核会周期性地的将**Dirty List**中的**Page**写入到磁盘中。

   

## Kafka与MMap

除了直接使用<span style=background:#c9ccff>Page Cache</span>，[**Kafka**还使用了**MMap**](http://mp.weixin.qq.com/s?__biz=MzIxMjAzMDA1MQ==&mid=2648945468&idx=1&sn=b622788361b384e152080b60e5ea69a7#rd&utm_source=tuicool&utm_medium=referral)来提高读写速度。

Memory Mapped Files，MMap，**内存映射文件** ，在64位操作系统中一般可以表示20G的数据文件。

> [20GB的内存按50MB/S的速度写入，至少可以缓存7分钟的消息](https://blog.csdn.net/suifeng3051/article/details/48053965#52-集群大小)。



## Zero Copy

普通的发送会有4次复制：

1. 从磁盘复制到内核空间的<span style=background:#c9ccff>Page Cache</span>。
2. 从<span style=background:#c9ccff>Page Cache</span>复制到<u>用户空间的缓存</u>。
3. 从<u>用户空间的缓存</u>复制到内核空间的<u>Socket缓存</u>。
4. 从<u>Socket缓存</u>复制到网卡缓存，然后发送。

而**Kafka**通过调用<span style=background:#b3b3b3>sendfile()</span>，直接从<span style=background:#c9ccff>Page Cache</span>复制到<u>Socket缓存</u>中，简化了步骤（将上述步骤中的2、3合并为一步），同时减少了用户态和内核态的切换，并且无需经过CPU。

> “[Zero Copy](https://www.cnblogs.com/rickiyang/p/13265043.html)”指的是只使用DMA，不使用CPU。
>
> <span style=background:#b3b3b3>sendfile()</span>是Linux方法，通过调用<span style=background:#b3b3b3>java.nio.channels.FileChannel.transferTo()</span>使用。



## 调优

沿着**Kafka**为追求高吞吐做出的设计，我们可以从以下几个方面进行调优：

1. Linux <span style=background:#c9ccff>Page Cache</span>参数调优。

2. [**Broker**参数调优](https://my.oschina.net/vivotech/blog/4524883)。

   > [参数大全](https://blog.csdn.net/suifeng3051/article/details/48053965#六kafka主要配置)

3. 开启压缩，**Producer**压缩，**Consumer**解压，以节省网络IO、提高吞吐。

   1. 压缩 / 解压会消耗CPU。
   2. **Kafka**支持Gzip、Snappy。

4. 按业务对**Cluster**进行资源隔离，避免不同业务因共享磁盘而相互影响。

5. 对**Cluster**用户的出入流量进行限制，避免流量突增。

6. 改造源码，对**Broker**，甚至是**Topic**进行流量限制。

7. 改造源码，对**Broker**进行<span style=background:#c2e2ff>负载均衡</span>。

8. 改造源码，实现副本并发、增量迁移，以减少IO。

9. 换用性能更好的固态硬盘，以及使用磁盘阵列。



## [基于SSD的Kafka缓存设计](https://tech.meituan.com/2021/01/14/kafka-ssd.html)

### Kafka在高负载时存在的问题

当**Producer**向**Kafka**中大量写入时，同一**Broker**上的不同**Partition**会出现竞争<span style=background:#c9ccff>Page Cache</span>的现象，相互影响，进而使该节点延迟上升、吞吐下降。

并且**Consumer**的消费能力往往是不同的，如果存在消费能力**Weak**的**Consumer**，则<span style=background:#c9ccff>Page Cache</span>会被弱**Weak Consumer**的数据占满，而**Strong Consumer**的数据会被大量刷写到硬盘上，这样**Strong Consumer**会失去<span style=background:#c9ccff>Page Cache</span>红利，而磁盘的读取也会增加，即延迟上升、吞吐下降。

而**Cluster**中往往存在着大量的**Weak Consumer**，减少**Weak Consumer**的方式不可行。

同时，传统机械硬盘的性能低，结合以上因素，美团为**Kafka**系统引入了固态硬盘作为缓存。（也可以纯修改软件，或者增大内存，但是这两种做法在美团看来太过复杂，并且不够经济）

### 解决方法比较

开源的缓存技术FlashCache、OpenCAS都提供了四种缓存策略：

1. WriteThrough：同时向SSD和HDD写入。
2. WriteBack：写入SSD后就算写入成功，之后再Flush到HDD。
3. WirteAround：直接写入HDD。
4. WriteThrough / WriteBack / WriteAround：首先读取SSD，命中不了则读取HDD，并数据会被刷入SSD中。

但是这些缓存技术不能很好地解决问题：

1. 这些缓存技术的核心是“数据局部性”原理，与**Kafka**的读写特性不相符。

   1. 数据回刷会污染SSD。

3. 同时其数据淘汰策略为LRU，还是会淘汰近实时数据，造成抖动。

所以美团采用了从**Kafka**内部修改，使用SSD存放将实时数据，同时不允许HDD数据回刷到SSD，以防污染。

### 具体方案

设计目标：

1. 将数据按时间维度分布，近实时数据放在SSD中，并随时间的推移淘汰到硬盘中
2. **Primary Partition**中的所有数据写入SSD。
3. 从HDD中读取的数据不回刷到SSD。

想要HDD上的数据不回刷SSD上，我们需要对**Segment**的状态进行标记，包括：

1. OnlyCache：只存储到SSD上。
2. Cached：后台线程定期将内存中Inactive（没有写流量）的**Segment**同步到SSD上。
3. WithoutCache：当SSD的空间使用达到阈值时，后台线程会将最古老的**Segment**从SSD中移除，**Segment**的状态也会改为WithoutCache。

完成这些之后并不代表着优化工作的完成，还有<span style=background:#c2e2ff>数据同步</span>和<span style=background:#c2e2ff>刷盘策略</span>两个问题需要解决：

##### 数据同步

1. 同步方式：出于对数据一致性维护成本、以及是否易于实现同步限速的考率，美团最终选择了，后台线程同步Inactive数据到HDD的方式。
2. 同步限速（最终一致性）：显然，如果不对同步加以限速，数据会蜂拥而至，出现性能毛刺。

##### 刷盘策略

1. 对单个**Segment**刷盘速率进行限制。