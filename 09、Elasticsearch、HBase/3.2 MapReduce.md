## 简介[[1]](https://cloud.tencent.com/developer/article/1431491#MapReduce运行原理)

**MapReduce**的核心思想是分治：

1. `map`：首先，将计算作业拆分为若干个任务，分配给不同的计算节点并行执行。
2. `barrier`：然后，对Map产生的中间结果进行聚合、整理（sorting, combining, partitioning,…）。
3. `reduce`：最后，将中间结果进行汇总。

> Map、Reduce源自函数式语言Lisp。
>
> 输入、中间结果、最终结果都保存在**HDFS**中。

![](../images/9/map-reduce-framework.png)

## 节点

### 作业跟踪器

<span style=background:#ffb8b8>Job Tracker</span>负责处理Client提交的作业、调度任务。

<span style=background:#ffb8b8>Job Tracker</span>负责决定哪些**Block**参与作业，并把作业分割为多个任务，并将这些执行Map、Reduce任务交给多个<span style=background:#f8d2ff>Task Tracker</span>执行。

### 任务跟踪器

<span style=background:#f8d2ff>Task Tracker</span>收到任务后会启动多个JVM，<span style=background:#f8d2ff>Task Tracker</span>会监控这些并行任务，还会重启失败的任务，当任务完成时，会向<span style=background:#ffb8b8>Job Tracker</span>报告。

<span style=background:#f8d2ff>Task Tracker</span>会定时向<span style=background:#ffb8b8>Job Tracker</span>发送心跳，报告任务的执行情况。

### 数量

一个集群只有一个<span style=background:#ffb8b8>Job Tracker</span>，但会有多个<span style=background:#f8d2ff>Task Tracker</span>。

<span style=background:#f8d2ff>Task Tracker</span>往往与<span style=background:#f8d2ff>Data Node</span>部署在同一台机器上，以节省网络开销；<span style=background:#f8d2ff>Data Node</span>上往往只会部署一个<span style=background:#f8d2ff>Task Tracker</span>。

![](../images/9/hadoop-node.svg)



## 处理过程

![](../images/9/map-reduce-processing.png)

#### Input Split

<span style=background:#ffb8b8>Job Tracker</span>将输入文件根据**Block**的大小进行分片，每个分片对应一个Map任务，如，有`3MB`、`129MB`两个不同大小的输入文件，会被分为`1MB`、`128MB`、`1MB`三个分片。

这里的切分不是真的将文件进行切分，而是保存文件的切分位置、分片的长度。

不难看出，每个分片的大小可能不均，而这正是编写**MapReduce**时的优化点。

#### Mapping

<span style=background:#f8d2ff>Task Tracker</span>根据分片执行开发者编写的`map()`，执行时尽量从本节点、本机架中读取数据。

#### Combine

<span style=background:#f8d2ff>Task Tracker</span>执行本地`reduce`，在`map()`计算出中间结果前对重复的<u>键值对</u>作简单的合并，执行完成后告知<span style=background:#ffb8b8>Job Tracker</span>。

#### Shuffle

将`map()`计算出的中间结果作为`reduce()`的输入，也是优化点。

#### Reduce

<span style=background:#f8d2ff>Task Tracker</span>执行开发者编写的`reduce()`，执行完成后告知<span style=background:#ffb8b8>Job Tracker</span>。



## 不足

随着<span style=background:#f8d2ff>Task Tracker</span>数量地增长，<span style=background:#ffb8b8>Job Tracker</span>的负担会变得很重；而“根据**Block**对任务进行划分”的方式太过简单，没有考虑CPU、内存、网络、磁盘等资源，<span style=background:#f8d2ff>Task Tracker</span>间的负载不均匀。

> <span style=background:#f8d2ff>Task Tracker</span>数量的上限大约为`4000`。

另外，**MapReduce**的源码可读性较差，难以维护。而且任何对于**MapReduce**的升级，都需要对整个**Hadoop**进行升级，并且需要对集群中的每个节点升级。

正是因为**MapReducer**存在诸多不足，所以就有了**YARN**。


